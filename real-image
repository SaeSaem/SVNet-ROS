#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include "opencv2/calib3d/calib3d.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include <pcl/io/pcd_io.h>
#include <pcl/point_types.h>

using namespace std;
using namespace cv;

static const std::string OPENCV_WINDOW = "Raw Image window";
static const std::string OPENCV_WINDOW_1 = "Edge Detection";

vector<Point3f> read_pcd();
vector<Point2f> getRT();
Mat display_image(Mat image);
vector<Point2f> Generate2DPoints();
vector<Point3f> Generate3DPoints();

// global variables
Mat cameraMatrix(3, 3, DataType<double>::type);
Mat distCoeffs(4, 1, DataType<double>::type);
Mat image, drawImg;
vector<Point2f> twoDpoints;

class Edge_Detector
{
  ros::NodeHandle nh_;
  image_transport::ImageTransport it_;
  image_transport::Subscriber image_sub_;
  image_transport::Publisher image_pub_;
  
public:
  Edge_Detector()
    : it_(nh_)
  {
    // Subscribe to input video feed and publish output video feed
    image_sub_ = it_.subscribe("/image_raw", 1, 
      &Edge_Detector::imageCb, this);
    image_pub_ = it_.advertise("/edge_detector/raw_image", 1);
    cv::namedWindow(OPENCV_WINDOW);

  }

  ~Edge_Detector()
  {
    cv::destroyWindow(OPENCV_WINDOW);
  }

  void imageCb(const sensor_msgs::ImageConstPtr& msg)
  {

    cv_bridge::CvImagePtr cv_ptr;
    namespace enc = sensor_msgs::image_encodings;

    try
    {
      cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
    }
    catch (cv_bridge::Exception& e)
    {
      ROS_ERROR("cv_bridge exception: %s", e.what());
      return;
    }

    // Draw an example circle on the video stream
    if (cv_ptr->image.rows > 400 && cv_ptr->image.cols > 600){

	mapping(cv_ptr->image);
    	image_pub_.publish(cv_ptr->toImageMsg());

	}
  }
  void mapping(Mat img)
  {
	twoDpoints = getRT(); // 2Dpoint from 3D point
	drawImg = display_image(img);        

	namedWindow("window", CV_WINDOW_AUTOSIZE); // Create a window for display.
	imshow("window", drawImg); // Show our image inside it.
	waitKey(3);

	//Mat src
//	circle(img, Point(100, 200), 5, Scalar(0, 255, 0), 2);
//	imshow(OPENCV_WINDOW, img);	
//	waitKey(3);

	//cv::Mat src, src_gray;
	//cv::Mat dst, detected_edges;

	//int edgeThresh = 1;
	//int lowThreshold = 200;
	//int highThreshold =300;
	//int kernel_size = 5;

	//img.copyTo(src);

	//cv::cvtColor( img, src_gray, CV_BGR2GRAY );
        //cv::blur( src_gray, detected_edges, cv::Size(5,5) );
	//cv::Canny( detected_edges, detected_edges, lowThreshold, highThreshold, kernel_size );

  	//dst = cv::Scalar::all(0);
  	//img.copyTo( dst, detected_edges);
	//dst.copyTo(img);

    	//cv::imshow(OPENCV_WINDOW, src);
    	//cv::imshow(OPENCV_WINDOW_1, dst);
    	//cv::waitKey(3);

  }	
 
};

int main(int argc, char** argv)
{
  ros::init(argc, argv, "Edge_Detector");
  Edge_Detector ic;
  ros::spin();
  return 0;
}

std::vector<cv::Point2f> getRT() {
	
	std::vector<cv::Point2f> imagePoints = Generate2DPoints();
	std::vector<cv::Point3f> objectPoints = Generate3DPoints();
	std::vector<cv::Point3f> objectPoints2 = read_pcd();

	cameraMatrix.at<double>(0, 0) = 1250.978;   // fx
	cameraMatrix.at<double>(0, 1) = 0;
	cameraMatrix.at<double>(0, 2) = 626.673;    // cx

	cameraMatrix.at<double>(1, 0) = 0;
	cameraMatrix.at<double>(1, 1) = 1257.900;    // fy
	cameraMatrix.at<double>(1, 2) = 354.239;     // cy

	cameraMatrix.at<double>(2, 0) = 0;
	cameraMatrix.at<double>(2, 1) = 0;
	cameraMatrix.at<double>(2, 2) = 1;

//	cout << "cameraMatrix" << endl;
//	cout << cameraMatrix << endl;

	distCoeffs.at<double>(0) = -0.318184;
	distCoeffs.at<double>(1) = 1.125858;
	distCoeffs.at<double>(2) = 0.004153;
	distCoeffs.at<double>(3) = -0.005453;

	cv::Mat rvec(3, 1, cv::DataType<double>::type);
	cv::Mat tvec(3, 1, cv::DataType<double>::type);

	cv::solvePnP(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec);

//	std::cout << "rvec: " << rvec << std::endl;
//	std::cout << "tvec: " << tvec << std::endl;

	Mat R;
	Rodrigues(rvec, R);
	Mat R_inv = R.inv();

	// camera position (X,Y,Z)
	Mat Cam_pos = -R_inv*tvec;
	double* p = (double*)Cam_pos.data;
	double X = p[0];
	double Y = p[1];
	double Z = p[2];


	std::vector<cv::Point2f> projectedPoints2;
	cv::projectPoints(objectPoints2, rvec, tvec, cameraMatrix, distCoeffs, projectedPoints2);

	for (unsigned int i = 0; i < projectedPoints2.size(); ++i)
	{
		//	cout << "Projected to" << projectedPoints2[i] << endl;
	}
	return projectedPoints2;
}

Mat display_image(Mat image) {

	//image = imread("result.jpg", CV_LOAD_IMAGE_COLOR);  
	if (!image.data)  // Check for invalid input
	{
		cout << "Could not open or find the image" << std::endl;
		return image;
	}

	int x, y;
	for (int i = 0; i < twoDpoints.size(); i++) {
		x = twoDpoints[i].x;
		y = twoDpoints[i].y;
		circle(image, Point(x, y), 1, Scalar(0, 0, 255), 2);
		//	image.at<Vec3b>(x, y)[2]= 255;
	}

	vector<Point2f> original = Generate2DPoints();
	for (int i = 0; i < original.size(); i++) {
		x = original[i].x;
		y = original[i].y;
		circle(image, Point(x, y), 1, Scalar(255, 0, 0), 2);
		//	image.at<Vec3b>(x, y)[2]= 255;
	}

	//DISPLAY image
//	namedWindow("window", CV_WINDOW_AUTOSIZE); // Create a window for display.
//	imshow("window", image); // Show our image inside it.

//	cout << "image size: " << image.rows << " x " << image.cols << endl;

//	waitKey(10);
	return image;
}

std::vector<cv::Point3f> read_pcd()
{
	std::vector<cv::Point3f> points2;
	pcl::PointCloud<pcl::PointXYZ>::Ptr cloud(new pcl::PointCloud<pcl::PointXYZ>);

	if (pcl::io::loadPCDFile<pcl::PointXYZ>("/home/saesaem/QuanergySystems/catkin_ws/src/cv_bridge_tutorial_pkg/src/filter.pcd", *cloud) == -1) //* load the file
	{
		PCL_ERROR("Couldn't read file test_pcd.pcd \n");
		return points2;
	}
//	std::cout << "Loaded "
//		<< cloud->width * cloud->height
//		<< " data points from test_pcd.pcd with the following fields: "
//		<< std::endl;

	//	std::vector<cv::Point3f> points2;
	int x2, y2, z2;
	for (size_t i = 0; i < cloud->points.size(); ++i) {

		x2 = cloud->points[i].x * 100;
		y2 = cloud->points[i].y * 100;
		z2 = cloud->points[i].z * 100;
		points2.push_back(cv::Point3f(x2, y2, z2));
	}
//	cout << points2.size() << endl;
	return points2;
}


std::vector<cv::Point2f> Generate2DPoints()
{
	std::vector<cv::Point2f> points;

	float x, y;

	x = 418; y = 340;
	points.push_back(cv::Point2f(x, y));
	x = 632; y = 358;
	points.push_back(cv::Point2f(x, y));
	x = 779; y = 297;
	points.push_back(cv::Point2f(x, y));
	x = 1068; y = 305;
	points.push_back(cv::Point2f(x, y));
//	for (unsigned int i = 0; i < points.size(); ++i)
//	{
//		std::cout << points[i] << std::endl;
//	}
	return points;
}

std::vector<cv::Point3f> Generate3DPoints()
{
	std::vector<cv::Point3f> points;
	float x, y, z;
	x = 465; y = 117; z = 0;
	points.push_back(cv::Point3f(x, y, z));
	x = 482; y = 29; z = 0;
	points.push_back(cv::Point3f(x, y, z));
	x = 365; y = -21; z = 20;
	points.push_back(cv::Point3f(x, y, z));
	x = 364; y = -101; z = 21;
	points.push_back(cv::Point3f(x, y, z));

//	for (unsigned int i = 0; i < points.size(); ++i)
//	{
//		std::cout << points[i] << std::endl;
//	}

	return points;
}
